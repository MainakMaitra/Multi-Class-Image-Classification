{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras import applications\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import cv2\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimensions of our images\n",
    "# dimensions of our images.  \n",
    "img_width, img_height = 224, 224  \n",
    "   \n",
    "top_model_weights_path = 'bottleneck_fc_model.h5'  \n",
    "train_data_dir = '/home/tukai/Videos/Activity Recognition/train'  \n",
    "validation_data_dir = '/home/tukai/Videos/Activity Recognition/validation'  \n",
    "   \n",
    "# number of epochs to train top model  \n",
    "epochs = 50  \n",
    "# batch size used by flow_from_directory and predict_generator  \n",
    "batch_size = 16  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_bottlebeck_features():\n",
    "    # build the VGG16 network\n",
    "    model = applications.VGG16(include_top=False, weights='imagenet')\n",
    "\n",
    "    datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "    generator = datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,\n",
    "        shuffle=False)\n",
    "\n",
    "    print(len(generator.filenames))\n",
    "    print(generator.class_indices)\n",
    "    print(len(generator.class_indices))\n",
    "\n",
    "    nb_train_samples = len(generator.filenames)\n",
    "    num_classes = len(generator.class_indices)\n",
    "\n",
    "    predict_size_train = int(math.ceil(nb_train_samples / batch_size))\n",
    "\n",
    "    bottleneck_features_train = model.predict_generator(\n",
    "        generator, predict_size_train)\n",
    "\n",
    "    np.save('bottleneck_features_train.npy', bottleneck_features_train)\n",
    "\n",
    "    generator = datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,\n",
    "        shuffle=False)\n",
    "\n",
    "    nb_validation_samples = len(generator.filenames)\n",
    "\n",
    "    predict_size_validation = int(\n",
    "        math.ceil(nb_validation_samples / batch_size))\n",
    "\n",
    "    bottleneck_features_validation = model.predict_generator(\n",
    "        generator, predict_size_validation)\n",
    "\n",
    "    np.save('bottleneck_features_validation.npy',\n",
    "            bottleneck_features_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_top_model():\n",
    "    datagen_top = ImageDataGenerator(rescale=1. / 255)\n",
    "    generator_top = datagen_top.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False)\n",
    "\n",
    "    nb_train_samples = len(generator_top.filenames)\n",
    "    num_classes = len(generator_top.class_indices)\n",
    "\n",
    "    # save the class indices to use use later in predictions\n",
    "    np.save('class_indices.npy', generator_top.class_indices)\n",
    "\n",
    "    # load the bottleneck features saved earlier\n",
    "    train_data = np.load('bottleneck_features_train.npy')\n",
    "\n",
    "    # get the class lebels for the training data, in the original order\n",
    "    train_labels = generator_top.classes\n",
    "\n",
    "    # convert the training labels to categorical vectors\n",
    "    train_labels = to_categorical(train_labels, num_classes=num_classes)\n",
    "\n",
    "    generator_top = datagen_top.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,\n",
    "        shuffle=False)\n",
    "\n",
    "    nb_validation_samples = len(generator_top.filenames)\n",
    "\n",
    "    validation_data = np.load('bottleneck_features_validation.npy')\n",
    "\n",
    "    validation_labels = generator_top.classes\n",
    "    validation_labels = to_categorical(\n",
    "        validation_labels, num_classes=num_classes)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=train_data.shape[1:]))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer='rmsprop',\n",
    "                  loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(train_data, train_labels,\n",
    "                        epochs=epochs,\n",
    "                        batch_size=batch_size,\n",
    "                        validation_data=(validation_data, validation_labels))\n",
    "\n",
    "    model.save_weights(top_model_weights_path)\n",
    "\n",
    "    (eval_loss, eval_accuracy) = model.evaluate(\n",
    "        validation_data, validation_labels, batch_size=batch_size, verbose=1)\n",
    "\n",
    "    print(\"[INFO] accuracy: {:.2f}%\".format(eval_accuracy * 100))\n",
    "    print(\"[INFO] Loss: {}\".format(eval_loss))\n",
    "\n",
    "    plt.figure(1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-ddca5c7f11a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m211\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    " # summarize history for accuracy\n",
    "\n",
    "plt.subplot(211)\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-283cdb72d4b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m212\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    " # summarize history for loss\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict():\n",
    "    # load the class_indices saved in the earlier step\n",
    "    class_dictionary = np.load('class_indices.npy').item()\n",
    "\n",
    "    num_classes = len(class_dictionary)\n",
    "\n",
    "    # add the path to your test image below\n",
    "    image_path = '/home/tukai/Videos/tennis.jpg'\n",
    "\n",
    "    orig = cv2.imread(image_path)\n",
    "\n",
    "    print(\"[INFO] loading and preprocessing image...\")\n",
    "    image = load_img(image_path, target_size=(224, 224))\n",
    "    image = img_to_array(image)\n",
    "\n",
    "    # important! otherwise the predictions will be '0'\n",
    "    image = image / 255\n",
    "\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "\n",
    "    # build the VGG16 network\n",
    "    model = applications.VGG16(include_top=False, weights='imagenet')\n",
    "\n",
    "    # get the bottleneck prediction from the pre-trained VGG16 model\n",
    "    bottleneck_prediction = model.predict(image)\n",
    "\n",
    "    # build top model\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=bottleneck_prediction.shape[1:]))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.load_weights(top_model_weights_path)\n",
    "\n",
    "    # use the bottleneck prediction on the top model to get the final\n",
    "    # classification\n",
    "    class_predicted = model.predict_classes(bottleneck_prediction)\n",
    "\n",
    "    probabilities = model.predict_proba(bottleneck_prediction)\n",
    "\n",
    "    inID = class_predicted[0]\n",
    "\n",
    "    inv_map = {v: k for k, v in class_dictionary.items()}\n",
    "\n",
    "    label = inv_map[inID]\n",
    "\n",
    "    # get the prediction label\n",
    "    print(\"Image ID: {}, Label: {}\".format(inID, label))\n",
    "\n",
    "    # display the predictions with the image\n",
    "    cv2.putText(orig, \"Predicted: {}\".format(label), (10, 30),\n",
    "                cv2.FONT_HERSHEY_PLAIN, 1.5, (43, 99, 255), 2)\n",
    "\n",
    "    cv2.imshow(\"Classification\", orig)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    # save the model to disk\n",
    "    filename = '/home/tukai/Videos/Activity Recognition/finalized_model.sav'\n",
    "    pickle.dump(model, open(filename, 'wb'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1672 images belonging to 5 classes.\n",
      "1672\n",
      "{'Skating dance': 0, 'Skating race': 1, 'skiing': 2, 'swimming': 3, 'tennis': 4}\n",
      "5\n",
      "Found 1501 images belonging to 5 classes.\n",
      "Found 1672 images belonging to 5 classes.\n",
      "Found 1501 images belonging to 5 classes.\n",
      "Train on 1672 samples, validate on 1501 samples\n",
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 8s 5ms/step - loss: 3.6526 - acc: 0.2554 - val_loss: 1.3998 - val_acc: 0.5889\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 7s 4ms/step - loss: 3.1940 - acc: 0.5281 - val_loss: 1.6426 - val_acc: 0.8141\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 7s 4ms/step - loss: 1.8478 - acc: 0.7356 - val_loss: 0.3478 - val_acc: 0.9340\n",
      "Epoch 4/50\n",
      "1672/1672 [==============================] - 7s 4ms/step - loss: 0.5184 - acc: 0.8846 - val_loss: 0.1201 - val_acc: 0.9667\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 7s 4ms/step - loss: 0.3267 - acc: 0.9282 - val_loss: 0.0514 - val_acc: 0.9853\n",
      "Epoch 6/50\n",
      "1672/1672 [==============================] - 7s 4ms/step - loss: 0.2089 - acc: 0.9402 - val_loss: 0.0254 - val_acc: 0.9920\n",
      "Epoch 7/50\n",
      "1672/1672 [==============================] - 7s 4ms/step - loss: 0.1565 - acc: 0.9587 - val_loss: 0.1699 - val_acc: 0.9660\n",
      "Epoch 8/50\n",
      "1672/1672 [==============================] - 7s 4ms/step - loss: 0.1385 - acc: 0.9629 - val_loss: 0.0098 - val_acc: 0.9967\n",
      "Epoch 9/50\n",
      "1672/1672 [==============================] - 7s 4ms/step - loss: 0.1027 - acc: 0.9743 - val_loss: 0.0084 - val_acc: 0.9960\n",
      "Epoch 10/50\n",
      "1672/1672 [==============================] - 7s 4ms/step - loss: 0.0913 - acc: 0.9737 - val_loss: 0.0101 - val_acc: 0.9960\n",
      "Epoch 11/50\n",
      "1672/1672 [==============================] - 7s 4ms/step - loss: 0.0605 - acc: 0.9821 - val_loss: 0.0092 - val_acc: 0.9980\n",
      "Epoch 12/50\n",
      "1672/1672 [==============================] - 7s 4ms/step - loss: 0.0630 - acc: 0.9833 - val_loss: 0.0106 - val_acc: 0.9947\n",
      "Epoch 13/50\n",
      "1672/1672 [==============================] - 7s 4ms/step - loss: 0.0695 - acc: 0.9856 - val_loss: 0.0085 - val_acc: 0.9987\n",
      "Epoch 14/50\n",
      "1672/1672 [==============================] - 7s 4ms/step - loss: 0.0990 - acc: 0.9779 - val_loss: 0.0024 - val_acc: 0.9993\n",
      "Epoch 15/50\n",
      "1672/1672 [==============================] - 7s 4ms/step - loss: 0.0352 - acc: 0.9892 - val_loss: 0.0110 - val_acc: 0.9967\n",
      "Epoch 16/50\n",
      "1672/1672 [==============================] - 7s 4ms/step - loss: 0.0776 - acc: 0.9850 - val_loss: 0.0054 - val_acc: 0.9987\n",
      "Epoch 17/50\n",
      "1672/1672 [==============================] - 7s 4ms/step - loss: 0.0349 - acc: 0.9928 - val_loss: 4.7915e-04 - val_acc: 1.0000\n",
      "Epoch 18/50\n",
      "1672/1672 [==============================] - 7s 4ms/step - loss: 0.0360 - acc: 0.9916 - val_loss: 1.7252e-06 - val_acc: 1.0000\n",
      "Epoch 19/50\n",
      "1672/1672 [==============================] - 7s 4ms/step - loss: 0.0331 - acc: 0.9940 - val_loss: 0.0091 - val_acc: 0.9987\n",
      "Epoch 20/50\n",
      "1672/1672 [==============================] - 7s 4ms/step - loss: 0.0379 - acc: 0.9922 - val_loss: 0.0102 - val_acc: 0.9987\n",
      "Epoch 21/50\n",
      "1392/1672 [=======================>......] - ETA: 1s - loss: 0.0279 - acc: 0.9950"
     ]
    }
   ],
   "source": [
    "save_bottlebeck_features()\n",
    "train_top_model()\n",
    "predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving environment: \\ "
     ]
    }
   ],
   "source": [
    "!conda install -c conda-forge jupyter_contrib_nbextensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
